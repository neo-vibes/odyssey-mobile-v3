# Agentic Engineering Workflow

## Overview

A structured workflow where Claude Code orchestrates sub-agents to build software from specs. Uses iterative "Ralph loops" to ensure quality through multiple passes.

## Architecture

```
SPECS
  │
  ▼
┌─────────────────────────────────────────────┐
│ ORCHESTRATOR (high reasoning model)         │
│ - Reads project specs                       │
│ - Generates tasks.json                      │
│ - Defines: complexity, deps, model, iters   │
│ - Manages task execution order              │
└─────────────────────────────────────────────┘
  │
  ▼
For each task (ordered by dependencies):
  │
  ├── Ralph Loop (N iterations based on complexity)
  │     ├── Iter 1 → sub-agent (clean context) → status/logs
  │     ├── Iter 2 (+ iteration memory) → sub-agent → status/logs
  │     └── Iter N → success or fail
  │
  ├── If fail: New Ralph Loop (+ last iteration notes/logs)
  │     └── Fresh loop, carries forward learnings
  │
  └── Task complete or blocked
  │
  ▼
Code Quality Ralph Loop(s)
  │
  └── Cleanup/polish pass, same iteration pattern
  │
  ▼
DONE
```

## Components

### 1. Orchestrator

The main Claude Code instance (high reasoning model) that:
- Parses SPECS to understand project requirements
- Generates `tasks.json` with task breakdown
- Determines execution order from dependencies
- Spawns Ralph loops for each task
- Evaluates results and decides: done / retry / blocked
- Runs final code quality loop

### 2. tasks.json

Generated by orchestrator from specs:

```json
{
  "tasks": [
    {
      "id": "task-id",
      "name": "Task Name",
      "description": "What to build",
      "complexity": "low|medium|high",
      "iterations": 2,
      "model": "sonnet",
      "dependencies": ["other-task-id"],
      "acceptance": [
        "Criteria 1",
        "Criteria 2"
      ]
    }
  ]
}
```

**Fields:**
- `complexity` — Informs iteration count
- `iterations` — Ralph loop iterations (low=1-2, medium=2-3, high=3-5)
- `model` — Sub-agent model (sonnet for most, opus for complex)
- `dependencies` — Task IDs that must complete first
- `acceptance` — Verifiable criteria including test commands

### 3. Ralph Loop

Iterative execution pattern for each task:

1. **Spawn sub-agent** with clean, task-scoped context
2. **Sub-agent executes** following framework rules
3. **Sub-agent returns** structured feedback:
   - Status: `success` | `partial` | `blocked`
   - What was done
   - Issues encountered
   - Iteration notes/logs
4. **Orchestrator evaluates** — continue iterating or done?
5. **Next iteration** receives previous iteration's notes/logs

**Memory flow:**
- Each iteration adds to loop memory
- If loop fails and restarts, last iteration's notes/logs carry forward
- Sub-agent always starts with clean context + injected memory

### 4. Sub-Agent Context

Each sub-agent spawn receives:

```
[Task Prompt]
- Task description
- Acceptance criteria
- Verification commands

[Framework Rules]
- Build before polish
- Verify with actual commands
- Return structured status

[Iteration Memory] (if not first iteration)
- Previous iteration notes/logs
- Known issues to address
```

### 5. Code Quality Loop

Final pass after all tasks complete:
- Same Ralph loop pattern
- Focus: lint, types, formatting, cleanup
- Orchestrator can run additional iterations if needed

## Workflow Rules

1. **Clean context per spawn** — Sub-agents don't accumulate context bloat
2. **Structured feedback** — Status/logs enable orchestrator decisions
3. **Iteration memory** — Learnings carry forward within and across loops
4. **Verification required** — Acceptance criteria include runnable commands
5. **Dependencies respected** — Task order follows dependency graph

## Files

| File | Purpose |
|------|---------|
| `WORKFLOW.md` | This file — architecture overview |
| `tasks-schema.md` | tasks.json schema details |
| `principles.md` | Core principles for sub-agents |
| `ralph-prompt-template.md` | Template for Ralph loop prompts |
| `agents-md-template.md` | AGENTS.md template for projects |
| `spec-template.md` | Template for project specs |

## Usage

### With Claude Code CLI (laptop)

1. Create project spec from `spec-template.md`
2. Start Claude Code in project directory
3. Claude Code reads spec, generates tasks.json
4. Claude Code orchestrates Ralph loops via Task tool
5. Review final output

### With OpenClaw (Neo)

1. Create project spec
2. Neo reads spec, generates tasks.json
3. Neo orchestrates Ralph loops via `sessions_spawn`
4. Review final output

Same workflow, different execution runtime.
